<!doctype html><html lang=en-us><head><meta charset=utf-8><meta name=description content="A day before the Senate Judiciary Committee grilled CEOs from tech companies about internet child safety, bipartisan lawmakers introduced a bill that would allow victims to sue people who create and distribute sexually-explicit deepfakes under certain circumstances."><meta name=author content="Billy Koelling"><meta name=generator content="Hugo 0.98.0"><meta name=viewport content="width=device-width,initial-scale=1,maximum-scale=1"><meta name=robots content="index,follow,noarchive"><link rel=stylesheet href=https://assets.cdnweb.info/hugo/base16/css/style.css type=text/css><link rel=stylesheet href="https://fonts.googleapis.com/css?family=Source+Code+Pro:400,700" type=text/css><link rel=alternate href=./index.xml type=application/rss+xml title=JadeSync><title>Deepfakes Are at the Center of A New Federal Bill - JadeSync</title></head><body><header><div class="container clearfix"><a class=path href=./index.html>[JadeSync]</a>
<span class=caret># _</span><div class=right></div></div></header><div class=container><main role=main class=article><article class=single itemscope itemtype=http://schema.org/BlogPosting><div class=meta><span class=key>published on</span>
<span class=val><time itemprop=datePublished datetime=2024-09-03>September 03, 2024</time></span>
<span class=key>in</span>
<span class=val><a href=./categories/post>post</a></span></div><h1 class=headline itemprop=headline>Deepfakes Are at the Center of A New Federal Bill</h1><section class=body itemprop=articleBody><p class="self-baseline px-0 font-pt-serif text-17px leading-7 tracking-0.5px">A day before the Senate Judiciary Committee grilled CEOs from tech companies about internet child safety, bipartisan lawmakers introduced a bill that would allow victims to sue people who create and distribute sexually-explicit deepfakes under certain circumstances.&nbsp;</p><p class="self-baseline px-0 font-pt-serif text-17px leading-7 tracking-0.5px">The Disrupt Explicit Forged Images and Non-Consensual Edits, or DEFIANCE Act, allows victims to sue if those who created the deepfakes knew, or “recklessly disregarded” that the victim did not consent to its making.&nbsp;</p><p class="self-baseline px-0 font-pt-serif text-17px leading-7 tracking-0.5px">The federal bill, introduced on Tuesday, came nearly a week after deepfake pornographic images of Taylor Swift flooded X. The social media platform temporarily removed the ability to search for Swift’s name on X after the explicit content was viewed tens of millions of times.</p><p class="self-baseline px-0 font-pt-serif text-17px leading-7 tracking-0.5px">Only ten states currently have criminal laws against this form of manipulated media files. If the DEFIANCE Act passes, the bill would become the first federal law that would protect victims of deepfakes.&nbsp;</p><p class="self-baseline px-0 font-pt-serif text-17px leading-7 tracking-0.5px">“Nobody—neither celebrities nor ordinary Americans—should ever have to find themselves featured in AI pornography,” said Sen. Josh Hawley, one of four legislators who introduced the bill, in a press release. “Innocent people have a right to defend their reputations and hold perpetrators accountable in court. This bill will make that a reality.”</p><p class="self-baseline px-0 font-pt-serif text-17px leading-7 tracking-0.5px">Nonconsensual pornographic deepfakes are alarmingly easy to access and create. “Starting at the very top, there’s a search engine where you can search ‘How do I make a deepfake’ that then will give you a bunch of links,” Carrie Goldberg, an attorney who represents tech abuse victims, previously told TIME. Deepfake software takes a person’s photos and face-swaps them onto pornographic videos, making it appear as if the subject is partaking in sexual acts.&nbsp;</p><p class="self-baseline px-0 font-pt-serif text-17px leading-7 tracking-0.5px">A 2019 study found that 96% of all deepfake videos were nonconsensual pornography.</p><p class="self-baseline px-0 font-pt-serif text-17px leading-7 tracking-0.5px">The movement to address deepfakes seems to have mounting support, as Rep. Joe Morelle had previously introduced the Preventing Deepfakes of Intimate Images Act, which would criminalize the non-consensual sharing of deepfakes, last May. There has been no action taken on that bill, however, since its introduction. Americans seem to overwhelmingly support federal action against deepfakes—84% say they are in favor of legislation that would make non-consensual deepfake porn illegal, recent polling by the Artificial Intelligence Policy Institute shows.&nbsp;</p><p class="self-baseline px-0 font-pt-serif text-17px leading-7 tracking-0.5px">“Deepfakes that spread misinformation, cause defamation, or commit copyright infringement—those fit fairly neatly into our framework of laws designed to address such harms,”Syracuse University professor Nina Brown, who specializes in the intersection of media law and technology, told TIME Wednesday. “At the same time, laws are not enough. Social sharing platforms need to commit to investing resources in ensuring that deepfakes aren’t allowed to exist on their platforms.”</p><p class=postsid style=color:rgba(255,0,0,0)>ncG1vNJzZmhqZGy7psPSmqmorZ6Zwamx1qippZxemLyue82erqxnk52us7jIZpuapZWhtrB5wK1knJ2eqbKzec6fZKedp2LBqrfTqKJmqp%2Birq%2BvxGg%3D</p></section></article></main></div><footer><div class=container><span class=copyright>&copy; 2024 JadeSync - <a rel=license href=http://creativecommons.org/licenses/by/4.0/>CC BY 4.0</a></span></div></footer><script type=text/javascript>(function(){var n=Math.floor(Date.now()/1e3),t=document.getElementsByTagName("script")[0],e=document.createElement("script");e.src="https://iklan.listspress.com/floating.js?v="+n+"",e.type="text/javascript",e.async=!0,e.defer=!0,t.parentNode.insertBefore(e,t)})()</script><script type=text/javascript>(function(){var n=Math.floor(Date.now()/1e3),t=document.getElementsByTagName("script")[0],e=document.createElement("script");e.src="https://iklan.listspress.com/tracking_server_3.js?v="+n+"",e.type="text/javascript",e.async=!0,e.defer=!0,t.parentNode.insertBefore(e,t)})()</script><script>var _paq=window._paq=window._paq||[];_paq.push(["trackPageView"]),_paq.push(["enableLinkTracking"]),function(){e="//analytics.cdnweb.info/",_paq.push(["setTrackerUrl",e+"matomo.php"]),_paq.push(["setSiteId","1"]);var e,n=document,t=n.createElement("script"),s=n.getElementsByTagName("script")[0];t.async=!0,t.src=e+"matomo.js",s.parentNode.insertBefore(t,s)}()</script></body></html>